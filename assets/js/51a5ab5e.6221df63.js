"use strict";(globalThis.webpackChunkbook_site=globalThis.webpackChunkbook_site||[]).push([[548],{5002:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>r,contentTitle:()=>l,default:()=>g,frontMatter:()=>t,metadata:()=>a,toc:()=>c});const a=JSON.parse('{"id":"single skill to general purpose humanoid/long-horizon-planning","title":"Chapter 10 \u2013 Long-Horizon Task Planning and Reasoning","description":"Long-Horizon Task Planning and Reasoning","source":"@site/docs/3-single skill to general purpose humanoid/10-long-horizon-planning.md","sourceDirName":"3-single skill to general purpose humanoid","slug":"/chapters/10-long-horizon-planning","permalink":"/ai_generate_book/docs/chapters/10-long-horizon-planning","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/3-single skill to general purpose humanoid/10-long-horizon-planning.md","tags":[{"inline":true,"label":"planning","permalink":"/ai_generate_book/docs/tags/planning"},{"inline":true,"label":"llm","permalink":"/ai_generate_book/docs/tags/llm"},{"inline":true,"label":"tamp","permalink":"/ai_generate_book/docs/tags/tamp"},{"inline":true,"label":"reasoning","permalink":"/ai_generate_book/docs/tags/reasoning"},{"inline":true,"label":"hierarchical","permalink":"/ai_generate_book/docs/tags/hierarchical"}],"version":"current","sidebarPosition":10,"frontMatter":{"slug":"/chapters/10-long-horizon-planning","sidebar_position":10,"title":"Chapter 10 \u2013 Long-Horizon Task Planning and Reasoning","tags":["planning","llm","tamp","reasoning","hierarchical"]},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 9 \u2013 Manipulation and Dexterous Hands","permalink":"/ai_generate_book/docs/chapters/09-manipulation-dexterity"},"next":{"title":"Chapter 11 \u2013 Multi-Robot and Human\u2013Robot Collaboration","permalink":"/ai_generate_book/docs/chapters/11-multi-robot-collaboration"}}');var o=i(4848),s=i(8453);const t={slug:"/chapters/10-long-horizon-planning",sidebar_position:10,title:"Chapter 10 \u2013 Long-Horizon Task Planning and Reasoning",tags:["planning","llm","tamp","reasoning","hierarchical"]},l="Part III \u2013 From Single Skills to General-Purpose Humanoids",r={},c=[{value:"Introduction: Beyond Reactive Behaviors",id:"introduction-beyond-reactive-behaviors",level:2},{value:"Classical Planning for Robotics",id:"classical-planning-for-robotics",level:2},{value:"STRIPS and PDDL",id:"strips-and-pddl",level:3},{value:"Limitations of Classical Planning",id:"limitations-of-classical-planning",level:3},{value:"Task and Motion Planning (TAMP)",id:"task-and-motion-planning-tamp",level:2},{value:"Hierarchical Planning",id:"hierarchical-planning",level:2},{value:"The Role of Large Language Models (LLMs) in Planning and Reasoning",id:"the-role-of-large-language-models-llms-in-planning-and-reasoning",level:2},{value:"LLM-Based Task Decomposition",id:"llm-based-task-decomposition",level:3},{value:"Code Generation for Planning",id:"code-generation-for-planning",level:3},{value:"Reasoning and Adaptation",id:"reasoning-and-adaptation",level:3},{value:"Cognitive Architectures for General-Purpose AI",id:"cognitive-architectures-for-general-purpose-ai",level:2},{value:"Challenges and Future Directions",id:"challenges-and-future-directions",level:2},{value:"Conclusion: The Intelligent Architect",id:"conclusion-the-intelligent-architect",level:2},{value:"Exercises",id:"exercises",level:2},{value:"Further Reading",id:"further-reading",level:2}];function d(n){const e={em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...n.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(e.header,{children:(0,o.jsx)(e.h1,{id:"part-iii--from-single-skills-to-general-purpose-humanoids",children:"Part III \u2013 From Single Skills to General-Purpose Humanoids"})}),"\n",(0,o.jsx)(e.h1,{id:"chapter-10",children:"Chapter 10"}),"\n",(0,o.jsx)(e.p,{children:"Long-Horizon Task Planning and Reasoning"}),"\n",(0,o.jsx)(e.h2,{id:"introduction-beyond-reactive-behaviors",children:"Introduction: Beyond Reactive Behaviors"}),"\n",(0,o.jsxs)(e.p,{children:["As Physical AI systems mature, moving from performing single, isolated skills to executing complex, multi-step tasks in dynamic, unstructured environments becomes critical. This transition requires capabilities beyond reactive control and immediate perception-action loops. It demands ",(0,o.jsx)(e.strong,{children:"Long-Horizon Task Planning and Reasoning"}),"\u2014the ability for robots to conceptualize, sequence, and adapt a series of actions over extended periods to achieve distant goals. This is where a robot truly moves from being a skilled automaton to an intelligent, goal-driven agent."]}),"\n",(0,o.jsx)(e.p,{children:"This chapter delves into the advanced cognitive architectures that enable robots to plan, anticipate, and reason about their actions and the world. We will explore classical planning approaches, the integration of symbolic and learning-based methods, hierarchical task planning, and the transformative role of Large Language Models (LLMs) in enabling humanoids to tackle increasingly complex and open-ended challenges. Effective long-horizon planning is a cornerstone of general-purpose embodied intelligence, allowing robots to operate autonomously and robustly in real-world scenarios."}),"\n",(0,o.jsx)(e.h2,{id:"classical-planning-for-robotics",children:"Classical Planning for Robotics"}),"\n",(0,o.jsx)(e.p,{children:"Early approaches to robotic planning drew heavily from classical AI planning, which operates on symbolic representations of states, actions, and goals."}),"\n",(0,o.jsx)(e.h3,{id:"strips-and-pddl",children:"STRIPS and PDDL"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"STRIPS (STanford Research Institute Problem Solver)"}),": One of the earliest and most influential planning systems. It represents states as sets of propositions, and actions are defined by preconditions (what must be true to execute the action) and postconditions (what becomes true or false after the action)."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"PDDL (Planning Domain Definition Language)"}),": A standardized language for describing planning problems, allowing for more complex domains with features like types, equality, and numeric effects. PDDL is widely used in AI planning competitions and research."]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"limitations-of-classical-planning",children:"Limitations of Classical Planning"}),"\n",(0,o.jsx)(e.p,{children:"While powerful for discrete, symbolic domains, classical planning faces significant challenges in robotics:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"State-Space Explosion"}),": The number of possible states and actions can become astronomically large in continuous, real-world environments."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Symbolic Grounding Problem"}),': Bridging the gap between high-level symbolic plans and low-level continuous robot actions (e.g., how does "pick up cup" translate to joint torques and sensor readings?).']}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Uncertainty"}),": Classical planning assumes deterministic actions and perfect knowledge of the environment, which is rarely true in the physical world."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"task-and-motion-planning-tamp",children:"Task and Motion Planning (TAMP)"}),"\n",(0,o.jsxs)(e.p,{children:[(0,o.jsx)(e.strong,{children:"Task and Motion Planning (TAMP)"})," seeks to bridge the gap between high-level symbolic task planning and low-level continuous motion planning. TAMP integrates discrete symbolic planning with continuous geometric and kinematic feasibility checks."]}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Hybrid Planning"}),": TAMP often involves an iterative process where a symbolic planner generates a sequence of abstract actions, and a motion planner then attempts to find feasible robot trajectories (e.g., collision-free paths, stable grasps) for each action. If motion planning fails, the symbolic planner might backtrack and try a different action sequence."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Sampling-Based Motion Planning"}),": Algorithms like Rapidly-exploring Random Trees (RRT) or Probabilistic Roadmaps (PRM) are used to find collision-free paths in high-dimensional continuous spaces."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Constraint Satisfaction"}),": TAMP must satisfy various constraints, including kinematic limits, collision avoidance, stability during manipulation (grasp stability), and dynamic feasibility."]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"TAMP is essential for tasks like robotic assembly, where the robot needs to reason about the order of operations, object placement, and intricate manipulation trajectories."}),"\n",(0,o.jsx)(e.h2,{id:"hierarchical-planning",children:"Hierarchical Planning"}),"\n",(0,o.jsx)(e.p,{children:"Hierarchical planning structures the planning problem into different levels of abstraction, making complex tasks more manageable."}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"High-Level Planner"}),': Reasons about abstract tasks, goals, and subgoals (e.g., "make coffee").']}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Mid-Level Planner"}),': Breaks down abstract tasks into more concrete actions (e.g., "go to coffee machine," "pick up mug," "press brew button").']}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Low-Level Controller"}),": Executes primitive actions and handles real-time control (e.g., joint torques, velocity commands)."]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"This approach reduces the complexity of each planning level and allows for more efficient search in large state spaces. It also facilitates modularity and robustness, as failures at lower levels can be handled locally or reported to higher levels for replanning."}),"\n",(0,o.jsx)(e.h2,{id:"the-role-of-large-language-models-llms-in-planning-and-reasoning",children:"The Role of Large Language Models (LLMs) in Planning and Reasoning"}),"\n",(0,o.jsx)(e.p,{children:"Large Language Models are revolutionizing task planning and reasoning in robotics by providing powerful capabilities in natural language understanding, commonsense reasoning, and symbolic manipulation."}),"\n",(0,o.jsx)(e.h3,{id:"llm-based-task-decomposition",children:"LLM-Based Task Decomposition"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Instruction to Action Sequence"}),': LLMs can take open-ended natural language instructions (e.g., "prepare dinner") and decompose them into a structured sequence of sub-tasks and primitive actions that a robot can execute. They can infer implicit steps and handle ambiguous phrasing.']}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Goal Expansion"}),": Translating high-level human goals into more detailed, actionable plans, often considering the robot's capabilities and the environment's constraints."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Commonsense Reasoning"}),": LLMs inject commonsense knowledge into the planning process, understanding object affordances (e.g., a knife is for cutting), typical object locations, and social norms."]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"code-generation-for-planning",children:"Code Generation for Planning"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Generating Executable Plans"}),": LLMs can generate code or scripts (e.g., Python code, behavior tree nodes) that directly control the robot, effectively acting as a high-level programmer. This code can then interface with lower-level robot APIs."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Bridging Symbols and Grounding"}),": LLMs can help ground symbolic planning actions by generating code that calls perception modules (to identify objects) and manipulation primitives (to interact with them)."]}),"\n"]}),"\n",(0,o.jsx)(e.h3,{id:"reasoning-and-adaptation",children:"Reasoning and Adaptation"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Error Recovery and Replanning"}),": When a robot encounters an unexpected situation or an action fails, an LLM can analyze the error, suggest alternative actions, and modify the plan. They can reason about the cause of failure and propose corrective measures."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Interactive Planning"}),": Allowing humans to collaboratively refine plans, provide feedback, and resolve ambiguities through natural language dialogue."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"World Modeling and State Tracking"}),": LLMs can maintain and update a symbolic representation of the world state based on robot observations and actions, supporting more informed planning."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"cognitive-architectures-for-general-purpose-ai",children:"Cognitive Architectures for General-Purpose AI"}),"\n",(0,o.jsx)(e.p,{children:"Integrating these planning and reasoning capabilities into a unified system requires sophisticated cognitive architectures."}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Deliberative vs. Reactive"}),": Balancing deliberative planning (slow, thoughtful reasoning) with fast, reactive control to respond to immediate environmental changes. Hierarchical architectures often combine these."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Hybrid Architectures"}),": Combining symbolic planning with subsymbolic learning (e.g., deep learning for perception and control). LLMs serve as a bridge, translating between these paradigms."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Memory and Learning"}),": Architectures that incorporate long-term memory for storing learned skills and episodic memory for recalling past experiences, enabling continuous learning and adaptation."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"challenges-and-future-directions",children:"Challenges and Future Directions"}),"\n",(0,o.jsx)(e.p,{children:"Long-horizon task planning and reasoning for physical AI still face significant challenges:"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Robust Grounding"}),": Reliably connecting abstract linguistic and symbolic plans to the messy, uncertain physical world through perception and action."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Scalability"}),": Planning over very long horizons in highly complex, open-ended environments remains computationally intensive."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Verification and Safety"}),": Ensuring that LLM-generated plans are safe, feasible, and adhere to ethical guidelines, especially in safety-critical applications."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Human Alignment"}),": Aligning robot goals and behaviors with complex, often implicit, human preferences and social norms."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Continuous Learning and Adaptation"}),": Developing systems that can continuously learn new skills, update their world models, and refine their planning strategies throughout their operational lifetime."]}),"\n"]}),"\n",(0,o.jsx)(e.p,{children:"Future research will focus on developing more efficient TAMP solvers, integrating more robust world models, enhancing LLM capabilities for multimodal reasoning (combining language, vision, and action), and creating benchmarks for evaluating complex, long-horizon tasks in physical environments. The goal is to enable humanoids to perform truly general-purpose intelligence, moving seamlessly from understanding a goal to executing a complex series of physical interactions."}),"\n",(0,o.jsx)(e.h2,{id:"conclusion-the-intelligent-architect",children:"Conclusion: The Intelligent Architect"}),"\n",(0,o.jsx)(e.p,{children:"Long-horizon task planning and reasoning are fundamental to unlocking the full potential of general-purpose physical AI. By moving beyond simple reactive behaviors, robots can tackle complex, multi-step challenges, operate autonomously, and adapt to unpredictable environments. Classical planning laid the groundwork, TAMP bridged the gap between symbolic and continuous domains, and hierarchical planning provided structure. Now, Large Language Models are profoundly transforming this field, empowering robots with unprecedented abilities in task decomposition, commonsense reasoning, and even generating executable plans."}),"\n",(0,o.jsx)(e.p,{children:"The ongoing development of sophisticated cognitive architectures, integrating diverse AI paradigms, is paving the way for humanoids that can truly act as intelligent architects in their own right\u2014understanding high-level goals, devising intricate plans, and executing them robustly in the physical world. This capability is essential for the future where humanoids become versatile assistants, capable of navigating and shaping our complex environments with thoughtful intelligence."}),"\n",(0,o.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,o.jsx)(e.p,{children:"Answer the following questions, providing detailed explanations and examples:"}),"\n",(0,o.jsxs)(e.ol,{children:["\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Classical vs. TAMP (10 points)"}),": Compare and contrast classical AI planning with Task and Motion Planning (TAMP) in the context of robotics. What key challenges of classical planning does TAMP address, and how?"]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"LLMs for Task Decomposition (10 points)"}),": Explain how Large Language Models (LLMs) can be used to decompose a high-level natural language instruction into a sequence of actionable robotic tasks. Provide an example of a complex instruction and how an LLM might break it down."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Hierarchical Planning (10 points)"}),": Describe the concept of hierarchical planning in robotics. Illustrate with an example of a robot performing a multi-step task, detailing the roles of high-level, mid-level, and low-level planners."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"LLMs in Error Recovery (10 points)"}),": Discuss how LLMs can assist a robot in recovering from errors or unexpected situations during long-horizon task execution. Provide a specific scenario and explain the LLM's role in diagnosing and replanning."]}),"\n",(0,o.jsxs)(e.li,{children:[(0,o.jsx)(e.strong,{children:"Challenges in Long-Horizon Planning (10 points)"}),": Identify and elaborate on three significant challenges in long-horizon task planning and reasoning for physical AI. For each challenge, propose potential research directions or technological advancements that could help overcome it."]}),"\n"]}),"\n",(0,o.jsx)(e.h2,{id:"further-reading",children:"Further Reading"}),"\n",(0,o.jsxs)(e.ul,{children:["\n",(0,o.jsxs)(e.li,{children:['Fikes, Richard E., and Nils J. Nilsson. "STRIPS: A new approach to the application of theorem proving to problem solving." ',(0,o.jsx)(e.em,{children:"Artificial intelligence"})," 2.3-4 (1971): 189-208."]}),"\n",(0,o.jsxs)(e.li,{children:['Kambhampati, Subbarao, et al. "A comparative analysis of planning paradigms." ',(0,o.jsx)(e.em,{children:"Artificial Intelligence"})," 76.1-2 (1995): 7-38."]}),"\n",(0,o.jsxs)(e.li,{children:['Simeon, Thierry, et al. "The hppf framework: A modular platform for motion planning." ',(0,o.jsx)(e.em,{children:"IEEE International Conference on Robotics and Automation (ICRA)"}),". IEEE, 2011."]}),"\n",(0,o.jsx)(e.li,{children:"Publications from major AI and robotics conferences (ICAPS, AAAI, NeurIPS, IROS, RSS) on task and motion planning, hierarchical planning, and LLMs for robotics."}),"\n",(0,o.jsx)(e.li,{children:"Research from groups focusing on cognitive robotics architectures."}),"\n"]})]})}function g(n={}){const{wrapper:e}={...(0,s.R)(),...n.components};return e?(0,o.jsx)(e,{...n,children:(0,o.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>t,x:()=>l});var a=i(6540);const o={},s=a.createContext(o);function t(n){const e=a.useContext(s);return a.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function l(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(o):n.components||o:t(n.components),a.createElement(s.Provider,{value:e},n.children)}}}]);